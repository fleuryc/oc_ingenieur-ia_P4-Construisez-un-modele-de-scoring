{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependancies\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import data.make_dataset as make_dataset\n",
    "import visualization.visualize as visualize\n",
    "import features.build_features as build_features\n",
    "\n",
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Prevent excessive memory usage\n",
    "DRAW_PLOTS = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data loading : set correct variable types\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read column names\n",
    "column_names = pd.read_csv(\n",
    "    \"../data/processed/application_train.csv\", nrows=0\n",
    ").columns.values\n",
    "\n",
    "# Set column types according to fields description (../data/raw/HomeCredit_columns_description.csv)\n",
    "column_types = {\n",
    "    col: \"category\"\n",
    "    for col in column_names\n",
    "    if col.startswith((\"NAME_\",))\n",
    "    or col.endswith((\"_TYPE\"))\n",
    "    or col\n",
    "    in [\n",
    "        \"CODE_GENDER\",\n",
    "        \"WEEKDAY_APPR_PROCESS_START\",\n",
    "        \"FONDKAPREMONT_MODE\",\n",
    "        \"HOUSETYPE_MODE\",\n",
    "        \"WALLSMATERIAL_MODE\",\n",
    "        \"EMERGENCYSTATE_MODE\",\n",
    "    ]\n",
    "}\n",
    "column_types |= {\n",
    "    col: bool\n",
    "    for col in column_names\n",
    "    if col.startswith((\"FLAG_\", \"REG_\", \"LIVE_\"))\n",
    "}\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/application_train.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ae7112b587e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m column_names = pd.read_csv(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"../data/processed/application_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ).columns.values\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p4/env/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/application_train.csv'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Application and Test data loading and first observations\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Application training data\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load application data\n",
    "app_train_df = pd.read_csv(\n",
    "    \"../data/processed/application_train.csv\",\n",
    "    dtype=column_types,\n",
    "    true_values=[\"Y\", \"Yes\", \"1\"],\n",
    "    false_values=[\"N\", \"No\", \"0\"],\n",
    "    na_values=[\"XNA\"],\n",
    ")\n",
    "\n",
    "# Application data features\n",
    "app_train_df.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Application data columns info\n",
    "app_train_df.info()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Application data variables description\n",
    "app_train_df.describe(include=\"all\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Application testing data\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load test data\n",
    "app_test_df = pd.read_csv(\n",
    "    \"../data/processed/application_test.csv\",\n",
    "    dtype=column_types,\n",
    "    true_values=[\"Y\", \"Yes\", \"1\"],\n",
    "    false_values=[\"N\", \"No\", \"0\"],\n",
    "    na_values=[\"XNA\"],\n",
    ")\n",
    "\n",
    "# Test data features\n",
    "app_test_df.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test data columns info\n",
    "app_test_df.info()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test data variables description\n",
    "app_test_df.describe(include=\"all\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis (EDA)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Look for empty columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot application columns emptiness ratio\n",
    "if DRAW_PLOTS:\n",
    "    visualize.plot_empty_values(app_train_df)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot test columns emptiness ratio\n",
    "if DRAW_PLOTS:\n",
    "    visualize.plot_empty_values(app_test_df)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All variables have less than 70% of empty values, which is considered enough for imputation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Look for impossible values and outliers\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove values that are outside possible range\n",
    "data_constraints = {\n",
    "    \"AMT_INCOME_TOTAL\": {\"min\": 0, \"max\": 20 * 1000 * 1000,},\n",
    "    \"DAYS_EMPLOYED\": {\"min\": -100 * 365, \"max\": 0,},\n",
    "    \"AMT_REQ_CREDIT_BUREAU_QRT\": {\"min\": 0, \"max\": 20,},\n",
    "    \"OBS_30_CNT_SOCIAL_CIRCLE\": {\"min\": 0, \"max\": 200,},\n",
    "    \"DEF_30_CNT_SOCIAL_CIRCLE\": {\"min\": 0, \"max\": 20,},\n",
    "    \"OBS_60_CNT_SOCIAL_CIRCLE\": {\"min\": 0, \"max\": 200,},\n",
    "    \"DEF_60_CNT_SOCIAL_CIRCLE\": {\"min\": 0, \"max\": 20,},\n",
    "}\n",
    "\n",
    "clean_app_train_df = build_features.drop_impossible_values(\n",
    "    app_train_df, constraints=data_constraints,\n",
    ")\n",
    "\n",
    "# Remove values that are statistically unlikely\n",
    "clean_app_train_df = build_features.drop_outliers(\n",
    "    clean_app_train_df, columns=[\"REGION_POPULATION_RELATIVE\"],\n",
    ")\n",
    "\n",
    "# Draw the BoxPlots of some numeric columns, split per Target\n",
    "columns_to_plot = [\n",
    "    \"AMT_INCOME_TOTAL\",\n",
    "    \"AMT_CREDIT\",\n",
    "    \"AMT_ANNUITY\",\n",
    "    \"AMT_GOODS_PRICE\",\n",
    "    \"DAYS_BIRTH\",\n",
    "    \"DAYS_EMPLOYED\",\n",
    "    \"OWN_CAR_AGE\",\n",
    "    \"REGION_RATING_CLIENT\",\n",
    "    \"REGION_RATING_CLIENT_W_CITY\",\n",
    "    \"EXT_SOURCE_1\",\n",
    "    \"EXT_SOURCE_2\",\n",
    "    \"EXT_SOURCE_3\",\n",
    "    \"DAYS_LAST_PHONE_CHANGE\",\n",
    "    \"AMT_REQ_CREDIT_BUREAU_YEAR\",\n",
    "]\n",
    "if DRAW_PLOTS:\n",
    "    visualize.plot_boxes(\n",
    "        dataframe=clean_app_train_df,\n",
    "        plot_columns=columns_to_plot,\n",
    "        categorical_column=\"TARGET\",\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove values that are outside possible range\n",
    "clean_app_test_df = build_features.drop_impossible_values(\n",
    "    app_test_df,\n",
    "    constraints=data_constraints,\n",
    ")\n",
    "\n",
    "# Remove values that are statistically unlikely \n",
    "clean_app_test_df = build_features.drop_outliers(\n",
    "    clean_app_test_df, columns=[\"REGION_POPULATION_RELATIVE\"],\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Look at categorical variables\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if DRAW_PLOTS:\n",
    "    # Draw the Bar charts of some categorical columns, split per Target\n",
    "    visualize.plot_categories_bars(\n",
    "        clean_app_train_df,\n",
    "        plot_columns=[\n",
    "            \"NAME_CONTRACT_TYPE\",\n",
    "            \"CODE_GENDER\",\n",
    "            \"FLAG_OWN_CAR\",\n",
    "            \"FLAG_OWN_REALTY\",\n",
    "            \"NAME_INCOME_TYPE\",\n",
    "            \"NAME_EDUCATION_TYPE\",\n",
    "            \"NAME_FAMILY_STATUS\",\n",
    "            \"NAME_HOUSING_TYPE\",\n",
    "            \"OCCUPATION_TYPE\",\n",
    "            \"FLAG_MOBIL\",\n",
    "        ],\n",
    "        categorical_column=\"TARGET\",\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### One Hot Encoding\n",
    "\n",
    "No ordinal data => One Hot Encoding is better than Label Encoding\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# One-hot encoding of categorical variables\n",
    "encoded_app_train_df = pd.get_dummies(clean_app_train_df, dtype=bool)\n",
    "encoded_app_test_df = pd.get_dummies(clean_app_test_df, dtype=bool)\n",
    "\n",
    "train_labels = encoded_app_train_df[\"TARGET\"]\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "encoded_app_train_df, encoded_app_test_df = encoded_app_train_df.align(\n",
    "    encoded_app_test_df, join=\"inner\", axis=1\n",
    ")\n",
    "\n",
    "# Add the target back in\n",
    "encoded_app_train_df[\"TARGET\"] = train_labels\n",
    "\n",
    "print(\"Training Features shape: \", encoded_app_train_df.shape)\n",
    "print(\"Testing Features shape: \", encoded_app_test_df.shape)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Missing values imputation\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If imputed data already exist, load from CSV\n",
    "# Else, do the imputation and save the data to CSV\n",
    "if os.path.exists(\"../data/processed/imputed_application_train.csv\"):\n",
    "    imputed_app_train_df = pd.read_csv(\n",
    "        \"../data/processed/imputed_application_train.csv\", index_col=0\n",
    "    )\n",
    "else:\n",
    "    imputed_app_train_df = build_features.impute_missing_values(\n",
    "        encoded_app_train_df\n",
    "    )\n",
    "    imputed_app_train_df.to_csv(\"../data/processed/imputed_application_train.csv\")\n",
    "\n",
    "\n",
    "if os.path.exists(\"../data/processed/imputed_application_test.csv\"):\n",
    "    imputed_app_test_df = pd.read_csv(\n",
    "        \"../data/processed/imputed_application_test.csv\", index_col=0\n",
    "    )\n",
    "else:\n",
    "    imputed_app_test_df = build_features.impute_missing_values(\n",
    "        encoded_app_test_df\n",
    "    )\n",
    "    imputed_app_test_df.to_csv(\"../data/processed/imputed_application_test.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Features selection\n",
    "\n",
    "Variables that are not highly correlated to an other, and at least a bit correlated to TARGET.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's compute the correlation matrix\n",
    "corrs_app_train_df = imputed_app_train_df.corr()\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.imshow(corrs_app_train_df,\n",
    "        title=\"Correlations between features\",\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "    )\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's drop variables that are highly de-correlated from TARGET\n",
    "\n",
    "simple_app_train_df = imputed_app_train_df.copy()\n",
    "simple_app_test_df = imputed_app_test_df.copy()\n",
    "\n",
    "highly_decorrelated_from_target_columns = pd.Series({})\n",
    "for col in corrs_app_train_df.columns:\n",
    "    if col != \"TARGET\" and (\n",
    "        pd.isnull(corrs_app_train_df[col][\"TARGET\"])\n",
    "        or abs(corrs_app_train_df[col][\"TARGET\"]) < 0.01\n",
    "    ):\n",
    "        highly_decorrelated_from_target_columns[col] = corrs_app_train_df[col][\n",
    "            \"TARGET\"\n",
    "        ]\n",
    "\n",
    "print(highly_decorrelated_from_target_columns.sort_values())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop irrelevant columns\n",
    "simple_app_train_df.drop(\n",
    "    columns=highly_decorrelated_from_target_columns.index,\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "simple_app_test_df.drop(\n",
    "    columns=highly_decorrelated_from_target_columns.index,\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "\n",
    "simple_app_train_df.shape\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's drop variables that have a highly correlated pair\n",
    "highly_correlated_columns = pd.DataFrame(columns=[\"pair\", \"correlation\"])\n",
    "for i in range(len(corrs_app_train_df.columns)):\n",
    "    for j in range(i + 1, len(corrs_app_train_df.columns)):\n",
    "        if i != j and abs(corrs_app_train_df.iloc[i, j]) > 0.9:\n",
    "            highly_correlated_columns.loc[corrs_app_train_df.columns[i]] = [\n",
    "                corrs_app_train_df.columns[j],\n",
    "                corrs_app_train_df.iloc[i, j],\n",
    "            ]\n",
    "\n",
    "print(highly_correlated_columns.sort_values(by=\"correlation\"))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "simple_app_train_df.drop(\n",
    "    columns=highly_correlated_columns.index, inplace=True, errors=\"ignore\",\n",
    ")\n",
    "simple_app_test_df.drop(\n",
    "    columns=highly_correlated_columns.index, inplace=True, errors=\"ignore\",\n",
    ")\n",
    "\n",
    "simple_app_train_df.shape\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "top_correlated_to_target_columns = (\n",
    "    pd.Series(\n",
    "        data={\n",
    "            col: corrs_app_train_df[col][\"TARGET\"]\n",
    "            for col in simple_app_train_df.columns.difference([\"TARGET\"])\n",
    "        }\n",
    "    )\n",
    "    .map(abs)\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.bar(\n",
    "        top_correlated_to_target_columns,\n",
    "        color=top_correlated_to_target_columns.values,\n",
    "        title=\"Top 20 Columns Correlated to Target\",\n",
    "        labels={\n",
    "            \"index\": \"Column name\",\n",
    "            \"value\": \"Correlation\",\n",
    "            \"color\": \"Correlation\",\n",
    "        },\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification models evaluation\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    explained_variance_score,\n",
    "    mean_squared_log_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    pairwise,\n",
    ")\n",
    "\n",
    "# Sample data\n",
    "sample_app_train_df = simple_app_train_df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Let's split the data into train and test sets\n",
    "X = sample_app_train_df[sample_app_train_df.columns.difference([\"TARGET\"])]\n",
    "y = sample_app_train_df[\"TARGET\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear models\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Linear Regression\n",
    "\n",
    "# - On apprend les coefficients d'une régression linéaire en maximisant le log de la vraisemblance, où, de manière équivalente si l'on suppose l'erreur normalement distribuée et centrée en zéro, en minimisant la somme des carrés des erreurs.\n",
    "# - Cette méthode s'appelle la méthode des moindres carrés.\n",
    "# - Si la matrice  $\\(X^\\top X\\)$ est inversible, la régression linéaire admet une solution unique et explicite.\n",
    "# - Sinon, on peut calculer une solution grâce à un algorithme de calcul de pseudo-inverse, mais cette solution n'est pas unique.\n",
    "\n",
    "\n",
    "# Variables must be :\n",
    "# - linear relationship with target\n",
    "# - i.i.d.\n",
    "# - error is normally distributed\n",
    "# - no outliers\n",
    "# - no missing values\n",
    "# - no multicollinearity\n",
    "# - numeric (categorical variables must be encoded)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "y_pred = lr.predict(X_test_std)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Best score: {lr.score(X_test_std, y_test):.4f}\",\n",
    "    f\"R2 score: {r2_score(y_test, y_pred):.3f}, \"\n",
    "    f\"MSE: {mean_squared_error(y_test, y_pred):.3f}, \"\n",
    "    f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}, \"\n",
    "    f\"EVS: {explained_variance_score(y_test, y_pred):.3f}\"\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "top_coefficients = pd.Series(lr.coef_, X.columns).map(abs).sort_values(ascending=False).head(20)\n",
    "\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.bar(\n",
    "        top_coefficients,\n",
    "        color=top_coefficients.values,\n",
    "        title=\"Top 20 Columns importance\",\n",
    "        labels={\n",
    "            \"index\": \"Column name\",\n",
    "            \"value\": \"Coefficient\",\n",
    "            \"color\": \"Coefficient\",\n",
    "        },\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Ridge Regression\n",
    "# Prevents overfitting by penalizing the magnitude of coefficients with L2 regularization of the loss function\n",
    "\n",
    "# - La norme ℓ2 du vecteur de poids peut être utilisée comme terme de régularisation de la régression linéaire.\n",
    "# - Cela s'appelle la régularisation de Tykhonov, ou régression ridge.\n",
    "# - La régression ridge admet toujours une solution analytique unique.\n",
    "# - La régression ridge permet d'éviter le surapprentissage en restraignant l'amplitude des poids.\n",
    "# - La régression ridge a un effet de sélection groupée : les variables corrélées ont le même coefficient.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "clf=RidgeCV(alphas=np.logspace(-3,7,50))\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Best alpha: {clf.alpha_:.3f}, \",\n",
    "    f\"Best score: {clf.score(X_test_std, y_test):.3f}, \",\n",
    "    f\"R2 score: {r2_score(y_test, y_pred):.3f}, \"\n",
    "    f\"MSE: {mean_squared_error(y_test, y_pred):.3f}, \"\n",
    "    f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}, \"\n",
    "    f\"EVS: {explained_variance_score(y_test, y_pred):.3f}\"\n",
    ")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "top_coefficients = pd.Series(clf.coef_, X.columns).map(abs).sort_values(ascending=False).head(20)\n",
    "\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    fig = px.bar(\n",
    "        top_coefficients,\n",
    "        color=top_coefficients.values,\n",
    "        title=\"Top 20 Columns importance\",\n",
    "        labels={\n",
    "            \"index\": \"Column name\",\n",
    "            \"value\": \"Coefficient\",\n",
    "            \"color\": \"Coefficient\",\n",
    "        },\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Compute paths\n",
    "\n",
    "fig = go.Figure()\n",
    "alphas = np.logspace(-3,7,50)\n",
    "coefficients = pd.DataFrame(index=X_train_std.columns, columns=alphas)\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(X_train_std, y_train)\n",
    "    coefficients.loc[:, a] = ridge.coef_\n",
    "\n",
    "\n",
    "for col in coefficients.index:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=alphas,\n",
    "            y=coefficients.loc[col,:],\n",
    "            name=col,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Display results\n",
    "\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Ridge coefficients as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"coefficient\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lasso Regression\n",
    "# Lasso is a special case of Ridge regression where the penalty is L1\n",
    "# Allows for sparse solutions by removing features with L1 regularization of the loss function\n",
    "\n",
    "# - Le lasso utilise la norme ℓ1 du vecteur β comme régularisateur pour obtenir un modèle parcimonieux.\n",
    "# - Le lasso peut donc être utilisé comme un algorithme de réduction de dimension supervisée.\n",
    "# - Le lasso n'a pas de solution explicite, ni nécessairement unique.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "\n",
    "clf=LassoCV(alphas=np.logspace(-5,3,50))\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "\n",
    "print(\n",
    "    f\"Best alpha: {clf.alpha_:.6f}, \",\n",
    "    f\"Best score: {clf.score(X_test_std, y_test):.3f}, \",\n",
    "    f\"R2 score: {r2_score(y_test, y_pred):.3f}, \"\n",
    "    f\"MSE: {mean_squared_error(y_test, y_pred):.3f}, \"\n",
    "    f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}, \"\n",
    "    f\"EVS: {explained_variance_score(y_test, y_pred):.3f}\"\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "top_coefficients = pd.Series(clf.coef_, X.columns).map(abs).sort_values(ascending=False).head(20)\n",
    "\n",
    "\n",
    "if True or DRAW_PLOTS:\n",
    "    fig = px.bar(\n",
    "        top_coefficients,\n",
    "        color=top_coefficients.values,\n",
    "        title=\"Top 20 Columns importance\",\n",
    "        labels={\n",
    "            \"index\": \"Column name\",\n",
    "            \"value\": \"Coefficient\",\n",
    "            \"color\": \"Coefficient\",\n",
    "        },\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alphas = np.logspace(-4, -1, 50)\n",
    "coefficients = pd.DataFrame(index=X.columns, columns=alphas)\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X_train_std, y_train)\n",
    "    coefficients.loc[:, a] = lasso.coef_\n",
    "    errors.append(mean_squared_error(y_test, lasso.predict(X_test_std)))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for col in coefficients.index:\n",
    "    fig.add_trace(go.Scatter(x=alphas, y=coefficients.loc[col, :], name=col,))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Lasso coefficients as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"coefficient\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=alphas, y=errors, name=\"MSE\",))\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Lasso MSE as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"MSE\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = go.Figure()\n",
    "for col in coefficients.index:\n",
    "    fig.add_trace(go.Scatter(x=alphas, y=coefficients.loc[col, :], name=col,))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Lasso coefficients as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"coefficient\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=alphas, y=errors, name=\"MSE\",))\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Lasso MSE as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"MSE\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Elastic Net\n",
    "# Elastic Net is a combination of Ridge and Lasso\n",
    "# Prevents overfitting by penalizing the magnitude of coefficients with L2 regularization of the loss function\n",
    "# Allows for sparse solutions by removing features with L1 regularization of the loss function\n",
    "\n",
    "# - L'elastic net combine les normes ℓ1 et ℓ2 pour obtenir une solution moins parcimonieuse que le lasso, mais plus stable et dans laquelle toutes les variables corrélées pertinentes pour la prédiction de l'étiquette sont sélectionnées et reçoivent un poids identique.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "alphas = np.logspace(-4, 0, 20)\n",
    "l1_ratios = np.linspace(0.01, 0.99, 10)\n",
    "clf = ElasticNetCV(alphas=alphas, l1_ratio=l1_ratios)\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Best alpha: {clf.alpha_:.6f}, \",\n",
    "    f\"Best l1_ratio: {clf.l1_ratio_:.6f}, \",\n",
    "    f\"Best score: {clf.score(X_test_std, y_test):.3f}, \",\n",
    "    f\"R2 score: {r2_score(y_test, y_pred):.3f}, \"\n",
    "    f\"MSE: {mean_squared_error(y_test, y_pred):.3f}, \"\n",
    "    f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}, \"\n",
    "    f\"EVS: {explained_variance_score(y_test, y_pred):.3f}\",\n",
    ")\n",
    "\n",
    "\n",
    "top_coefficients = (\n",
    "    pd.Series(clf.coef_, X.columns)\n",
    "    .map(abs)\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "\n",
    "if True or DRAW_PLOTS:\n",
    "    fig = px.bar(\n",
    "        top_coefficients,\n",
    "        color=top_coefficients.values,\n",
    "        title=\"Top 20 Columns importance\",\n",
    "        labels={\n",
    "            \"index\": \"Column name\",\n",
    "            \"value\": \"Coefficient\",\n",
    "            \"color\": \"Coefficient\",\n",
    "        },\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "coefficients = pd.DataFrame(index=X.columns, columns=alphas)\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    elastic = linear_model.ElasticNet(alpha=a, l1_ratio=clf.l1_ratio_)\n",
    "    elastic.fit(X_train_std, y_train)\n",
    "    coefficients.loc[:, a] = elastic.coef_\n",
    "    errors.append(mean_squared_error(y_test, elastic.predict(X_test_std)))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for col in coefficients.index:\n",
    "    fig.add_trace(go.Scatter(x=alphas, y=coefficients.loc[col, :], name=col,))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"ElasticNet coefficients as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"coefficient\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=alphas, y=errors, name=\"MSE\"))\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"ElasticNet MSE as a function of the regularization\",\n",
    "    xaxis_title=\"log(alpha)\",\n",
    "    yaxis_title=\"MSE\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logistic Regression\n",
    "#\n",
    "# - La régression logistique modélise la probabilité qu'une observation appartienne à la classe positive comme une transformation logistique d'une combinaison linéaire des variables.\n",
    "# - Les coefficients d'une régression logistique s'apprennent par maximisation de vraisemblance, mais il n'existe pas de solution explicite.\n",
    "# - La vraisemblance est convexe, et de nombreux solveurs peuvent être utilisés pour trouver une solution numérique.\n",
    "# - Les concepts de régularisation ℓ1 et ℓ2 s'appliquent aussi à la régression logistique.\n",
    "\n",
    "\n",
    "## StratifiedKFold\n",
    "# StratifiedKFold est un objet de type sklearn.model_selection.StratifiedKFold\n",
    "# Il permet de séparer les données en nombre de folds de manière stratifiée.\n",
    "# Les proportions des classes sont conservées.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "c_values = np.logspace(-3, 3, 10)\n",
    "l1_ratios = np.linspace(0.001, 0.999, 10)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        verbose=2,\n",
    "    ),\n",
    "    param_grid={\"C\": c_values, \"l1_ratio\": l1_ratios,},\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=4,\n",
    "    verbose=2,\n",
    ")\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "# print(\n",
    "#     \"Classification report : \",\n",
    "#     classification_report(y_true, y_pred),\n",
    "# )\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_clf = clf.best_estimator_\n",
    "\n",
    "top_coefficients = (\n",
    "    pd.Series(best_clf.coef_[0], X.columns)\n",
    "    .map(abs)\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "\n",
    "if True or DRAW_PLOTS:\n",
    "    fig = px.bar(\n",
    "        top_coefficients,\n",
    "        color=top_coefficients.values,\n",
    "        title=\"Top 20 Columns importance\",\n",
    "        labels={\n",
    "            \"index\": \"Column name\",\n",
    "            \"value\": \"Coefficient\",\n",
    "            \"color\": \"Coefficient\",\n",
    "        },\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "coefficients = pd.DataFrame(index=X.columns, columns=c_values)\n",
    "errors = []\n",
    "for c in c_values:\n",
    "    logistic = linear_model.LogisticRegression(C=c, l1_ratio=best_clf.l1_ratio_)\n",
    "    logistic.fit(X_train_std, y_train)\n",
    "    coefficients.loc[:, c] = logistic.coef_\n",
    "    errors.append(mean_squared_error(y_test, logistic.predict(X_test_std)))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for col in coefficients.index:\n",
    "    fig.add_trace(go.Scatter(x=c_values, y=coefficients.loc[col, :], name=col,))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Logistic regression coefficients as a function of the regularization\",\n",
    "    xaxis_title=\"log(C)\",\n",
    "    yaxis_title=\"coefficient\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=c_values, y=errors, name=\"MSE\"))\n",
    "fig.update_xaxes(type=\"log\", autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    title=\"Logistic regression MSE as a function of the regularization\",\n",
    "    xaxis_title=\"log(C)\",\n",
    "    yaxis_title=\"MSE\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Méthodes linéaire avec noyeau\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "# Linear SVC\n",
    "# - Les SVM (Support Vector Machines), aussi appelées en français Machines à Vecteurs de Support et parfois Séparatrices à Vaste Marge, cherchent à séparer linéairement les données.\n",
    "# - La version primale résout un problème d'optimisation à p variables et est donc préférable si on a moins de variables que d'échantillons.\n",
    "# - À l'inverse, la version duale résout un problème d'optimisation à n variables et est donc préférable si on a moins d'échantillons que de variables.\n",
    "# - Les vecteurs de support sont les points du jeu de données qui sont les plus proches de l'hyperplan séparateur.\n",
    "# - La fonction de décision peut s'exprimer uniquement en fonction du produit scalaire du point à étiqueter avec les vecteurs de support.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(X_train_std.shape)\n",
    "\n",
    "c_range = np.logspace(-2, 2, 2)\n",
    "gamma_range = np.logspace(-2, 2, 2)\n",
    "degree_range = np.arange(2, 3)\n",
    "kernel_range = [\"linear\", \"poly\", \"rbf\"]\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid={\n",
    "        \"C\": c_range,\n",
    "        \"gamma\": gamma_range,\n",
    "        \"degree\": degree_range,\n",
    "        \"kernel\": kernel_range,\n",
    "    },\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "# print(\n",
    "#     \"Classification report : \",\n",
    "#     classification_report(y_true, y_pred),\n",
    "# )\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmatrix = pairwise.rbf_kernel(X_train_std, gamma=clf.best_params_[\"gamma\"])\n",
    "kmatrix100 = kmatrix[:100, :100]\n",
    "\n",
    "# dessiner la matrice\n",
    "plt.pcolor(kmatrix100, cmap=matplotlib.cm.PuRd) \n",
    "\n",
    "# rajouter la légende\n",
    "plt.colorbar()\n",
    "\n",
    "# retourner l'axe des ordonnées\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().xaxis.tick_top()\n",
    "\n",
    "# afficher l'image\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Méthodes non linéaire\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid={\"n_neighbors\": [5, 10, 15], \"weights\": [\"uniform\", \"distance\"],},\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "# print(\n",
    "#     \"Classification report : \",\n",
    "#     classification_report(y_true, y_pred),\n",
    "# )\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Méthodes ensemblistes\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Bagging\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_estimator_range = [\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    # DecisionTreeClassifier(max_depth=5),\n",
    "    # DecisionTreeClassifier(max_depth=10),\n",
    "    # ElasticNet(),\n",
    "    # SVC(),\n",
    "]\n",
    "# [5, 10, 20, 50, 100]\n",
    "n_estimators_range = [100, 200, 500, 1000, 2000]\n",
    "max_samples_range = [100, 200, 500, 1000, 2000]\n",
    "max_features_range = [20] # [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=BaggingClassifier(random_state=42),\n",
    "    param_grid={\n",
    "        \"base_estimator\": base_estimator_range,\n",
    "        \"n_estimators\": n_estimators_range,\n",
    "        \"max_samples\": max_samples_range,\n",
    "        \"max_features\": max_features_range,\n",
    "    },\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=4,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "# print(\n",
    "#     \"Classification report : \",\n",
    "#     classification_report(y_true, y_pred),\n",
    "# )\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "disp = plot_precision_recall_curve(clf, X_test_std, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid={\n",
    "        \"n_estimators\": [100, 200, 500, 1000],\n",
    "        \"max_depth\": [10, 20, 50],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    },\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "# print(\n",
    "#     \"Classification report : \",\n",
    "#     classification_report(y_true, y_pred),\n",
    "# )\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42),\n",
    "    param_grid={\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.1, 0.3, 0.5],\n",
    "    },\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "# print(\n",
    "#     \"Classification report : \",\n",
    "#     classification_report(y_true, y_pred),\n",
    "# )\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n",
    "\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=42),\n",
    "    param_grid={\n",
    "        \"hidden_layer_sizes\": [(2,), (2,3,), (2,3,5,), (2,5,3,), (3,), (3,5,), (5,3,), (5,), (10,), (20,)],\n",
    "        \"alpha\": np.logspace(-5, 1, 5),\n",
    "    },\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=4,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_std)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ROC AUC score : \", roc_auc_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"ROC curve score : \", roc_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Accuracy score : \", accuracy_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision score : \", precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Recall score : \", recall_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"F1 score : \", f1_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Confusion matrix : \", confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Precision-Recall curve : \", precision_recall_curve(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Average precision score : \", average_precision_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"R2 score : \", r2_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error : \", mean_squared_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean absolute error : \", mean_absolute_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Explained variance score : \", explained_variance_score(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Mean squared log error : \", mean_squared_log_error(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"Median absolute error : \", median_absolute_error(y_true, y_pred),\n",
    ")\n",
    "\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_test_std)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    \"2-class Precision-Recall curve: AP={0:0.2f}\".format(average_precision)\n",
    ")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (conda)"
  },
  "interpreter": {
   "hash": "87142f5ce831c365860d10ab1d6251a6bfb068b987aa68f91a7996e4fcdedd96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}