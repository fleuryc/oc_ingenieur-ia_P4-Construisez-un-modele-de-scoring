{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prêt à dépenser : Construire un modèle de scoring\n",
    "\n",
    "\n",
    "## Contexte\n",
    "\n",
    "\"Prêt à dépenser\" (Home Credit) est une société financière qui propose des crédits à la consommation pour des personnes ayant peu ou pas d'historique de prêt.\n",
    "Pour accorder un crédit à la consommation, l'entreprise calcule la probabilité qu'un client le rembourse, ou non. Elle souhaite donc développer un algorithme de scoring pour aider à décider si un prêt peut être accordé à un client.\n",
    "\n",
    "Les chargés de relation client seront les utilisateurs du modèle de scoring. Puisqu'ils s'adressent aux clients, ils ont besoin que votre modèle soit facilement interprétable. Les chargés de relation souhaitent, en plus, disposer d'une mesure de l'importance des variables qui ont poussé le modèle à donner cette probabilité à un client.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chargement des modules du projet\n",
    "\n",
    "Afin de simplifier le Notebook, le code métier du projet est placé dans le répertoire [src/](../src/).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import project modules from source directory\n",
    "\n",
    "# system modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Append source directory to system path\n",
    "src_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# helper functions\n",
    "import data.helpers as data_helpers\n",
    "import features.helpers as feat_helpers\n",
    "import visualization.helpers as vis_helpers\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons utiliser le langage [Python](https://www.python.org/about/gettingstarted/), et présenter ici le code, les résultats et l'analyse sous forme de [Notebook JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html).\n",
    "\n",
    "Nous allons aussi utiliser les bibliothèques usuelles d'exploration et analyse de données, afin d'améliorer la simplicité et la performance de notre code :\n",
    "  * [NumPy](https://numpy.org/doc/stable/user/quickstart.html) et [Pandas](https://pandas.pydata.org/docs/user_guide/index.html) : effectuer des calculs scientifiques (statistiques, algèbre, ...) et manipuler des séries et tableaux de données volumineuses et complexes\n",
    "  * [scikit-learn](https://scikit-learn.org/stable/getting_started.html) et [XGBoost](https://xgboost.readthedocs.io/en/latest/get_started.html) : pour effectuer des analyses prédictives \n",
    "  * [Matplotlib](https://matplotlib.org/stable/tutorials/introductory/usage.html), [Pyplot](https://matplotlib.org/stable/tutorials/introductory/pyplot.html), [Seaborn](https://seaborn.pydata.org/tutorial/function_overview.html) et [Plotly](https://plotly.com/python/getting-started/) : générer des graphiques lisibles, intéractifs et pertinents\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prevent excessive memory usage used by plotly\n",
    "DRAW_PLOTS: bool = True\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chargement des données\n",
    "\n",
    "Les données mises à disposition sont issues de [Home Credit](https://www.homecredit.net/) et plus précisément de la compétition hébergée sur Kaggle [Home Credit Default Risk - Can you predict how capable each applicant is of repaying a loan?](https://www.kaggle.com/c/home-credit-default-risk)\n",
    "\n",
    "Les données sont fournies sous la forme de plusieurs fichiers CSV pouvant être liés entre eux de la manière suivante :\n",
    "\n",
    "![Home Credit data relations](https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png)\n",
    "\n",
    "_source : [Introduction: Home Credit Default Risk Competition](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction) by [Will Koehrsen](https://www.kaggle.com/willkoehrsen)_\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download and extract the raw data\n",
    "data_helpers.download_extract_zip(\n",
    "    zip_file_url=\"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Impl%C3%A9menter+un+mod%C3%A8le+de+scoring/Projet+Mise+en+prod+-+home-credit-default-risk.zip\",\n",
    "    files_names=(\n",
    "        \"application_test.csv\",\n",
    "        \"application_train.csv\",\n",
    "        \"bureau_balance.csv\",\n",
    "        \"bureau.csv\",\n",
    "        \"credit_card_balance.csv\",\n",
    "        \"installments_payments.csv\",\n",
    "        \"POS_CASH_balance.csv\",\n",
    "        \"previous_application.csv\",\n",
    "    ),\n",
    "    target_path=\"../data/raw/\",\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons charger toutes les données des fichiers `application_{train|test}.csv` dans le même DataFrame, afin de travailler les données en commun des jeux d'entraînement (variable `TARGET` vaut `O` : le client n'a pas fait défaut ou `1` : le client a fait défaut) et de test(variable `TARGET` non définie). Nous les séparerons à nouveau au moment de l'entrainement et évaluation de nos modèles.\n",
    "\n",
    "Les fichiers contiennent un grand nombre de variables booléennes et categorielles que nous pouvons déjà typer comme telles.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read column names\n",
    "application_train_column_names = pd.read_csv(\n",
    "    \"../data/raw/application_train.csv\", nrows=0\n",
    ").columns.values\n",
    "application_test_column_names = pd.read_csv(\n",
    "    \"../data/raw/application_test.csv\", nrows=0\n",
    ").columns.values\n",
    "\n",
    "# TARGET variable must be present in the Train datase\n",
    "if \"TARGET\" not in application_train_column_names:\n",
    "    raise ValueError(\n",
    "        \"TARGET column not found in application_train.csv. Please check that the file is not corrupted.\"\n",
    "    )\n",
    "\n",
    "# SK_ID_CURR variable must be present in the Train datase\n",
    "if \"SK_ID_CURR\" not in application_train_column_names:\n",
    "    raise ValueError(\n",
    "        \"SK_ID_CURR column not found in application_train_column_names.csv. Please check that the file is not corrupted.\"\n",
    "    )\n",
    "\n",
    "# Train and Test datasets must have the same variables, except for the TARGET variable\n",
    "if list(\n",
    "    application_train_column_names[application_train_column_names != \"TARGET\"]\n",
    ") != list(application_test_column_names):\n",
    "    raise ValueError(\n",
    "        \"Column names in application_train.csv and application_test.csv do not match. Please check that the files are not corrupted.\"\n",
    "    )\n",
    "\n",
    "# Set column types according to fields description (../data/raw/HomeCredit_columns_description.csv)\n",
    "# Categorical variables\n",
    "column_types = {\n",
    "    col: \"category\"\n",
    "    for col in application_train_column_names\n",
    "    if col.startswith((\"NAME_\",))\n",
    "    or col.endswith((\"_TYPE\"))\n",
    "    or col\n",
    "    in [\n",
    "        \"CODE_GENDER\",\n",
    "        \"WEEKDAY_APPR_PROCESS_START\",\n",
    "        \"FONDKAPREMONT_MODE\",\n",
    "        \"HOUSETYPE_MODE\",\n",
    "        \"WALLSMATERIAL_MODE\",\n",
    "        \"EMERGENCYSTATE_MODE\",\n",
    "    ]\n",
    "}\n",
    "# Boolean variables\n",
    "column_types |= {\n",
    "    col: bool\n",
    "    for col in application_train_column_names\n",
    "    if col.startswith((\"FLAG_\", \"REG_\", \"LIVE_\"))\n",
    "}\n",
    "\n",
    "# Load application data\n",
    "app_train_df = pd.read_csv(\n",
    "    \"../data/raw/application_train.csv\",\n",
    "    dtype=column_types,\n",
    "    true_values=[\"Y\", \"Yes\", \"1\"],\n",
    "    false_values=[\"N\", \"No\", \"0\"],\n",
    "    na_values=[\"XNA\"],\n",
    ")\n",
    "app_test_df = pd.read_csv(\n",
    "    \"../data/raw/application_test.csv\",\n",
    "    dtype=column_types,\n",
    "    true_values=[\"Y\", \"Yes\", \"1\"],\n",
    "    false_values=[\"N\", \"No\", \"0\"],\n",
    "    na_values=[\"XNA\"], # bad values\n",
    ")\n",
    "app_test_df['TARGET'] = -1 # identify test data\n",
    "\n",
    "# Merge Train and Test datasets\n",
    "app_df = app_train_df.append(app_test_df)\n",
    "\n",
    "# Let's display basic statistical info about the data\n",
    "app_df.describe(include=\"all\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "app_df.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le jeu de données contient 122 variables, dont la variable cible que nous devons estimer : `TARGET`. Parmis ces variables, nous avons :\n",
    "- 34 variables booléennes\n",
    "- 14 variables catégorielles\n",
    "- 74 variables numériques"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse exploratoire\n",
    "\n",
    "Nous allons analyser la distribution de quelques variables.\n",
    "\n",
    "### Variable cible\n",
    "\n",
    "Voyons spécifiquement la distribution de la variable `TARGET` qui est celle que nous devrons estimer par la suite.\n",
    "Les valeurs nulles représentent notre jeu d'entrainement.\n",
    "Nous pouvons oberver que nous avons à faire à un problème de __classification binaire déséquilibré__ (il y a deux valeurs possibles, mais les deux valeurs ne sont pas également représentées).\n",
    "Ceci va influencer la manière dont nous allons construire et entraîner notre modèle.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's plot the distribution of the TARGET variable\n",
    "if DRAW_PLOTS:\n",
    "    px.bar(\n",
    "        app_df[\"TARGET\"].replace({\n",
    "            \"0\": \"0 : payments OK\", \n",
    "            \"1\": \"1 : payment difficulties\", \n",
    "            \"-1\": \"-1 : undefined (test dataset)\",\n",
    "        }).value_counts(),\n",
    "        title=\"Distribution of TARGET variable\",\n",
    "        width=800,\n",
    "        height=400,\n",
    "    ).update_xaxes(\n",
    "        title=\"TARGET\",\n",
    "    ).update_yaxes(title=\"Count\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Valeurs vides\n",
    "\n",
    "Nous voyons que toutes les variables ont moins de 30% de valeurs vides, et près de la moitié a moins de 1% de valeurs vides. Le jeu de données est donc relativement bien rempli, ce qui ne devrait pas poser de problème pour la suite.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's display variables with missing values ratio\n",
    "if DRAW_PLOTS:\n",
    "    vis_helpers.plot_empty_values(app_df)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Valeurs impossibles\n",
    "\n",
    "Quelques valeurs présentes dans les données semblent impossibles. Nous allons supprimer ces \"outliers\".\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define data constraints\n",
    "data_constraints = {\n",
    "    \"DAYS_EMPLOYED\": {\"min\": -35000, \"max\": 0,}, # max 100 years, only negative values\n",
    "}\n",
    "\n",
    "if DRAW_PLOTS:\n",
    "    # Let's display box plots for variables with outliers\n",
    "    vis_helpers.plot_boxes(app_df, plot_columns=data_constraints.keys(), categorical_column=\"TARGET\")\n",
    "\n",
    "# Remove values that are outside possible range\n",
    "app_df = feat_helpers.drop_impossible_values(\n",
    "    app_df, constraints=data_constraints,\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variables quantitatives\n",
    "\n",
    "Nous allons simplement afficher la distribution de quelques variables numériques. Nous voyons déjà que selon la valeur de TARGET, la distribution (moyenne) des variables peut être sensiblement différente.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Draw the BoxPlots of some numeric columns, split per Target\n",
    "if DRAW_PLOTS:\n",
    "    vis_helpers.plot_boxes(app_df,\n",
    "        plot_columns=[\n",
    "            \"AMT_INCOME_TOTAL\",\n",
    "            \"AMT_CREDIT\",\n",
    "            \"AMT_ANNUITY\",\n",
    "            \"AMT_GOODS_PRICE\",\n",
    "            \"DAYS_BIRTH\",\n",
    "            \"DAYS_EMPLOYED\",\n",
    "            \"OWN_CAR_AGE\",\n",
    "            \"REGION_RATING_CLIENT\",\n",
    "            \"REGION_RATING_CLIENT_W_CITY\",\n",
    "            \"EXT_SOURCE_1\",\n",
    "            \"EXT_SOURCE_2\",\n",
    "            \"EXT_SOURCE_3\",\n",
    "            \"DAYS_LAST_PHONE_CHANGE\",\n",
    "            \"AMT_REQ_CREDIT_BUREAU_YEAR\",\n",
    "        ],\n",
    "        categorical_column=\"TARGET\",\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variables qualitatives\n",
    "\n",
    "De la même manière, nous allons simplement afficher la distribution de quelques variables catégorielles. Nous voyons déjà que selon la valeur de TARGET, la distribution (répartition entre classes) des variables peut être sensiblement différente (`TARGET=0` pour 77,6% des `NAME_CONTRACT_TYPE=\"Cash loans\"`, tandis que `TARGET=0` pour 93,1% des `NAME_CONTRACT_TYPE=\"Revolving loans\"`).\n",
    "Certaines variables ont une répartition très inégale entre classes (`FLAG_MOBIL` vaut systématiquement `True` et jamais `False`).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Draw the Bar charts of some categorical columns, split per Target\n",
    "if DRAW_PLOTS:\n",
    "    vis_helpers.plot_categories_bars(app_df,\n",
    "        plot_columns=[\n",
    "            \"NAME_CONTRACT_TYPE\",\n",
    "            \"CODE_GENDER\",\n",
    "            \"FLAG_OWN_CAR\",\n",
    "            \"FLAG_OWN_REALTY\",\n",
    "            \"NAME_INCOME_TYPE\",\n",
    "            \"NAME_EDUCATION_TYPE\",\n",
    "            \"NAME_FAMILY_STATUS\",\n",
    "            \"NAME_HOUSING_TYPE\",\n",
    "            \"OCCUPATION_TYPE\",\n",
    "            \"FLAG_MOBIL\",\n",
    "        ],\n",
    "        categorical_column=\"TARGET\",\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = app_df.loc[app_df[\"TARGET\"] >= 0].drop([\"TARGET\"], axis=1)\n",
    "y = app_df.loc[app_df[\"TARGET\"] >= 0, \"TARGET\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Afin d'apporter plus de sens aux données que nous allons fournir à nos modèles, nous pouvons faire appel aux experts métier qui peuvent nous indiquer des informations qui sont réputées importantes afin de prédire si un client risque d'avoir des problèmes de remboursement ou non.\n",
    "\n",
    "Les informations métier pertinentes sont :\n",
    "- Montant emprunté / Prix du bien acheté : `AMT_CREDIT / AMT_GOODS_PRICE`\n",
    "- Montant des annuités / Montant emprunté : `AMT_ANNUITY / AMT_CREDIT`\n",
    "- Montant des annuités / Revenu annuel : `AMT_ANNUITY / AMT_INCOME_TOTAL`\n",
    "- Ancienneté au travail / Age : `DAYS_EMPLOYED / DAYS_BIRTH`\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the new features\n",
    "feat_app_df = app_df.copy()\n",
    "feat_app_df[\"CREDIT_PRICE_RATIO\"]=feat_app_df[\"AMT_CREDIT\"]/feat_app_df[\"AMT_GOODS_PRICE\"]\n",
    "feat_app_df[\"ANNUITY_CREDIT_RATIO\"]=feat_app_df[\"AMT_ANNUITY\"]/feat_app_df[\"AMT_CREDIT\"]\n",
    "feat_app_df[\"ANNUITY_INCOME_RATIO\"]=feat_app_df[\"AMT_ANNUITY\"]/feat_app_df[\"AMT_INCOME_TOTAL\"]\n",
    "feat_app_df[\"EMPLOYED_BIRTH_RATIO\"]=feat_app_df[\"DAYS_EMPLOYED\"]/feat_app_df[\"DAYS_BIRTH\"]\n",
    "\n",
    "# Draw the BoxPlots for these features\n",
    "if DRAW_PLOTS:\n",
    "    vis_helpers.plot_boxes(feat_app_df,\n",
    "        plot_columns=[\n",
    "            \"CREDIT_PRICE_RATIO\",\n",
    "            \"ANNUITY_CREDIT_RATIO\",\n",
    "            \"ANNUITY_INCOME_RATIO\",\n",
    "            \"EMPLOYED_BIRTH_RATIO\",\n",
    "        ],\n",
    "        categorical_column=\"TARGET\",\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_feat = feat_app_df.loc[feat_app_df[\"TARGET\"] >= 0].drop([\"TARGET\"], axis=1)\n",
    "X_feat_train, X_feat_test, y_feat_train, y_feat_test = train_test_split(X_feat, y, test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Préparation des données\n",
    "\n",
    "Afin que nos modèles puissent exploiter au mieux les données, nous allons les transformer.\n",
    "\n",
    "\n",
    "### Encodage des catégories\n",
    "\n",
    "Lorsque les données qualitatives ne sont pas ordinales (on ne peu pas les classer selon un certain ordre), l'encodage \"One Hot Encoding\" sera plus performant que le \"Label Encoding\".\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Encode categorical variables with One Hot Encoding\n",
    "encoded_app_df = pd.get_dummies(feat_app_df, dtype=bool)\n",
    "\n",
    "encoded_app_df.describe(include=\"all\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_encoded = encoded_app_df.loc[encoded_app_df[\"TARGET\"] >= 0].drop([\"TARGET\"], axis=1)\n",
    "X_encoded_train, X_encoded_test, y_encoded_train, y_encoded_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons ici créé 133 nouvelles variables booléennes qui correspondent aux différentes classes de chacune des 14 anciennes variables catégorielles qui ont été encodées et supprimées.\n",
    "\n",
    "\n",
    "### Normalisation des données\n",
    "\n",
    "Afin d'éviter que certains modèles pondèrent l'importance de certaines variables à cause de leur ordre de grandeur, nous allons normaliser chaque variable afin de les ramener à une moyenne nulle et une variance de 1.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Scale each variable of the DataFrame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# define scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on train data only, to avoid data leak\n",
    "scaler.fit(X_encoded_train)\n",
    "# transform the dataset\n",
    "scaled_app_df = pd.DataFrame(\n",
    "    scaler.transform(X_encoded), columns=X_encoded.columns, index=X_encoded.index\n",
    ")\n",
    "\n",
    "scaled_app_df[\"TARGET\"] = y\n",
    "scaled_app_df.describe(include=\"all\")\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          SK_ID_CURR   FLAG_OWN_CAR  FLAG_OWN_REALTY   CNT_CHILDREN  \\\n",
       "count  252137.000000  252137.000000    252137.000000  252137.000000   \n",
       "mean        0.001472       0.000350        -0.003197      -0.000650   \n",
       "std         0.999864       1.000093         1.001230       0.999214   \n",
       "min        -1.730642      -0.773443        -1.457802      -0.653360   \n",
       "25%        -0.864812      -0.773443        -1.457802      -0.653360   \n",
       "50%         0.000980      -0.773443         0.685964      -0.653360   \n",
       "75%         0.867471       1.292920         0.685964       0.655950   \n",
       "max         1.733855       1.292920         0.685964      24.223535   \n",
       "\n",
       "       AMT_INCOME_TOTAL     AMT_CREDIT    AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "count     252137.000000  252137.000000  252125.000000    251881.000000   \n",
       "mean          -0.000245      -0.000268      -0.000399        -0.000189   \n",
       "std            0.909802       1.000003       1.000471         0.999706   \n",
       "min           -0.528387      -1.393533      -1.764798        -1.363165   \n",
       "25%           -0.223130      -0.820459      -0.733916        -0.808767   \n",
       "50%           -0.064966      -0.221947      -0.135488        -0.266422   \n",
       "75%            0.124831       0.535554       0.532710         0.384392   \n",
       "max          410.608725       8.458235      15.723622         9.375275   \n",
       "\n",
       "       REGION_POPULATION_RELATIVE     DAYS_BIRTH  ...  \\\n",
       "count               252137.000000  252137.000000  ...   \n",
       "mean                     0.001206       0.000149  ...   \n",
       "std                      1.002669       1.000114  ...   \n",
       "min                     -1.487858      -2.848137  ...   \n",
       "25%                     -0.785686      -0.762753  ...   \n",
       "50%                     -0.146533       0.053706  ...   \n",
       "75%                      0.562649       0.817737  ...   \n",
       "max                      3.731312       1.988086  ...   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  \\\n",
       "count             252137.000000             252137.000000   \n",
       "mean                  -0.000676                 -0.001246   \n",
       "std                    0.998135                  0.992970   \n",
       "min                   -0.175574                 -0.088228   \n",
       "25%                   -0.175574                 -0.088228   \n",
       "50%                   -0.175574                 -0.088228   \n",
       "75%                   -0.175574                 -0.088228   \n",
       "max                    5.695597                 11.334312   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "count                  252137.000000              252137.000000   \n",
       "mean                        0.000243                  -0.000122   \n",
       "std                         1.001556                   0.999178   \n",
       "min                        -0.077782                  -0.073676   \n",
       "25%                        -0.077782                  -0.073676   \n",
       "50%                        -0.077782                  -0.073676   \n",
       "75%                        -0.077782                  -0.073676   \n",
       "max                        12.856491                  13.572916   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "count             252137.000000                    252137.000000   \n",
       "mean                   0.002029                        -0.001475   \n",
       "std                    1.001409                         0.998964   \n",
       "min                   -0.522845                        -0.519530   \n",
       "25%                   -0.522845                        -0.519530   \n",
       "50%                   -0.522845                        -0.519530   \n",
       "75%                   -0.522845                        -0.519530   \n",
       "max                    1.912612                         1.924815   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_No  \\\n",
       "count              252137.000000           252137.000000   \n",
       "mean                   -0.000317               -0.000204   \n",
       "std                     0.998842                1.000011   \n",
       "min                    -0.134077               -1.042947   \n",
       "25%                    -0.134077               -1.042947   \n",
       "50%                    -0.134077                0.958821   \n",
       "75%                    -0.134077                0.958821   \n",
       "max                     7.458419                0.958821   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_Yes         TARGET  \n",
       "count            252137.000000  252137.000000  \n",
       "mean                 -0.000520       0.086600  \n",
       "std                   0.997082       0.281248  \n",
       "min                  -0.088456       0.000000  \n",
       "25%                  -0.088456       0.000000  \n",
       "50%                  -0.088456       0.000000  \n",
       "75%                  -0.088456       0.000000  \n",
       "max                  11.305098       1.000000  \n",
       "\n",
       "[8 rows x 245 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252125.000000</td>\n",
       "      <td>251881.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "      <td>252137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.003197</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>0.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>1.000093</td>\n",
       "      <td>1.001230</td>\n",
       "      <td>0.999214</td>\n",
       "      <td>0.909802</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>1.000471</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>1.002669</td>\n",
       "      <td>1.000114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>0.992970</td>\n",
       "      <td>1.001556</td>\n",
       "      <td>0.999178</td>\n",
       "      <td>1.001409</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>1.000011</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.281248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.730642</td>\n",
       "      <td>-0.773443</td>\n",
       "      <td>-1.457802</td>\n",
       "      <td>-0.653360</td>\n",
       "      <td>-0.528387</td>\n",
       "      <td>-1.393533</td>\n",
       "      <td>-1.764798</td>\n",
       "      <td>-1.363165</td>\n",
       "      <td>-1.487858</td>\n",
       "      <td>-2.848137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175574</td>\n",
       "      <td>-0.088228</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>-0.073676</td>\n",
       "      <td>-0.522845</td>\n",
       "      <td>-0.519530</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>-1.042947</td>\n",
       "      <td>-0.088456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.864812</td>\n",
       "      <td>-0.773443</td>\n",
       "      <td>-1.457802</td>\n",
       "      <td>-0.653360</td>\n",
       "      <td>-0.223130</td>\n",
       "      <td>-0.820459</td>\n",
       "      <td>-0.733916</td>\n",
       "      <td>-0.808767</td>\n",
       "      <td>-0.785686</td>\n",
       "      <td>-0.762753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175574</td>\n",
       "      <td>-0.088228</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>-0.073676</td>\n",
       "      <td>-0.522845</td>\n",
       "      <td>-0.519530</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>-1.042947</td>\n",
       "      <td>-0.088456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000980</td>\n",
       "      <td>-0.773443</td>\n",
       "      <td>0.685964</td>\n",
       "      <td>-0.653360</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.221947</td>\n",
       "      <td>-0.135488</td>\n",
       "      <td>-0.266422</td>\n",
       "      <td>-0.146533</td>\n",
       "      <td>0.053706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175574</td>\n",
       "      <td>-0.088228</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>-0.073676</td>\n",
       "      <td>-0.522845</td>\n",
       "      <td>-0.519530</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>0.958821</td>\n",
       "      <td>-0.088456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.867471</td>\n",
       "      <td>1.292920</td>\n",
       "      <td>0.685964</td>\n",
       "      <td>0.655950</td>\n",
       "      <td>0.124831</td>\n",
       "      <td>0.535554</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.384392</td>\n",
       "      <td>0.562649</td>\n",
       "      <td>0.817737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175574</td>\n",
       "      <td>-0.088228</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>-0.073676</td>\n",
       "      <td>-0.522845</td>\n",
       "      <td>-0.519530</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>0.958821</td>\n",
       "      <td>-0.088456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.733855</td>\n",
       "      <td>1.292920</td>\n",
       "      <td>0.685964</td>\n",
       "      <td>24.223535</td>\n",
       "      <td>410.608725</td>\n",
       "      <td>8.458235</td>\n",
       "      <td>15.723622</td>\n",
       "      <td>9.375275</td>\n",
       "      <td>3.731312</td>\n",
       "      <td>1.988086</td>\n",
       "      <td>...</td>\n",
       "      <td>5.695597</td>\n",
       "      <td>11.334312</td>\n",
       "      <td>12.856491</td>\n",
       "      <td>13.572916</td>\n",
       "      <td>1.912612</td>\n",
       "      <td>1.924815</td>\n",
       "      <td>7.458419</td>\n",
       "      <td>0.958821</td>\n",
       "      <td>11.305098</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 245 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X_scaled = scaled_app_df.loc[scaled_app_df[\"TARGET\"] >= 0].drop([\"TARGET\"], axis=1)\n",
    "X_scaled_train, X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons ici équilibré les ordres de grandeur de chaque variables, afin que nos fututs modèles ne soient pas influencés par leur différence.\n",
    "\n",
    "\n",
    "### Imputation des valeurs manquantes\n",
    "\n",
    "Afin d'éviter que certains modèles ne puissent être utilisés à cause des valeurs manquantes, nous allons remplacer toutes les valeurs nulles par leur meilleure estimation possible.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Impute missing values by modeling each feature with missing values as a function of other features in a round-robin fashion\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "# define imputer\n",
    "imputer = IterativeImputer(n_nearest_features=10, verbose=2)\n",
    "# fit scaler on train data only, to avoid data leak\n",
    "imputer.fit(X_scaled_train)\n",
    "# transform the dataset\n",
    "imputed_app_df = pd.DataFrame(\n",
    "    imputer.transform(X_scaled), columns=X_scaled.columns, index=X_scaled.index,\n",
    ")\n",
    "\n",
    "imputed_app_df[\"TARGET\"] = y\n",
    "imputed_app_df.describe(include=\"all\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_imputed = imputed_app_df.loc[imputed_app_df[\"TARGET\"] >= 0].drop([\"TARGET\"], axis=1)\n",
    "X_imputed_train, X_imputed_test, y_imputed_train, y_imputed_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.2, random_state=42\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Annexe\n",
    "\n",
    "Les Notebooks Kaggle [Introduction: Home Credit Default Risk Competition](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction) (et suivants) de [Will Koehrsen](https://www.kaggle.com/willkoehrsen) ont été d'une très grande aide dans l'exploration des données.\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87142f5ce831c365860d10ab1d6251a6bfb068b987aa68f91a7996e4fcdedd96"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}